{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60cad586-e162-4af7-a505-dd655b805c0d",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "\n",
    "Since this second job builds on top of the alignment, we need to supply the directories we specified before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f82f3d1-fe5c-4b0d-9564-0707b8c826a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHAFOLD_MODEL_DIR = \"af3models\"\n",
    "\n",
    "project_name = \"test\"\n",
    "\n",
    "ALPHAFOLD_WORKING_DIR=\"afold_test/\"\n",
    "ALPHAFOLD_RESULTS_DIR_PART1 = ALPHAFOLD_WORKING_DIR+\"output\" \n",
    "\n",
    "# the input for part II is the output of part I\n",
    "ALPHAFOLD_JSON_PATH_PART2 = ALPHAFOLD_RESULTS_DIR_PART1+\"/\"+project_name+\"/\"+project_name+\"_data.json\"\n",
    "\n",
    "\n",
    "# new output directory\n",
    "ALPHAFOLD_RESULTS_DIR_PART2 = ALPHAFOLD_WORKING_DIR+\"output_gpu/\" \n",
    "\n",
    "# I can also get this from the run.sh file, if I wanted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f03787-154f-4081-be58-ecf10cf554ba",
   "metadata": {},
   "source": [
    "## Input File\n",
    "Now we can use these directories to run the second part of the structure prediction. The input json file for AlphaFold is already written into the ALPHAFOLD_RESULTS_DIR/project_name. \n",
    "\n",
    "Note that larger prediction runs might require different settings in the start of the jupyter session!\n",
    "\n",
    "Fill in the sequence and chain ids, and remember the project name in \"name\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc151613-5b08-40d7-ad3d-08f7a665ad2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_file = f'''\n",
    "#!/bin/bash\n",
    "# AlphaFold 3 - Part 2: Inference (GPU required)\n",
    "\n",
    "# Load software module \n",
    "module load bio/alphafold/3.0.1\n",
    "\n",
    "# Run with option --norun_data_pipeline for featurisation and model inference\n",
    "python $ALPHAFOLD_BIN_DIR/run_alphafold.py \\\\\n",
    "    --json_path={ALPHAFOLD_JSON_PATH_PART2} \\\\\n",
    "    --db_dir=$ALPHAFOLD_DATABASES \\\\\n",
    "    --model_dir={ALPHAFOLD_MODEL_DIR} \\\\\n",
    "    --output_dir={ALPHAFOLD_RESULTS_DIR_PART2} \\\\\n",
    "    --norun_data_pipeline\n",
    "\n",
    "'''\n",
    "\n",
    "ALPHAFOLD_RUN_PATH = ALPHAFOLD_WORKING_DIR+\"run_gpu.sh\"\n",
    "\n",
    "with open(ALPHAFOLD_RUN_PATH, \"w\") as file:\n",
    "    file.write(run_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39acd06d-8fdf-4477-a23e-35fbb2df07af",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "nbval-ignore-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0722 11:34:47.045928 22835066345280 xla_bridge.py:895] Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'\n",
      "I0722 11:34:47.046923 22835066345280 xla_bridge.py:895] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory\n",
      "Running AlphaFold 3. Please note that standard AlphaFold 3 model parameters are\n",
      "only available under terms of use provided at\n",
      "https://github.com/google-deepmind/alphafold3/blob/main/WEIGHTS_TERMS_OF_USE.md.\n",
      "If you do not agree to these terms and are using AlphaFold 3 derived model\n",
      "parameters, cancel execution of AlphaFold 3 inference with CTRL-C, and do not\n",
      "use the model parameters.\n",
      "Skipping running the data pipeline.\n",
      "Found local devices: [CudaDevice(id=0)], using device 0: cuda:0\n",
      "Building model from scratch...\n",
      "Processing fold inputs.\n",
      "Processing fold input #1\n",
      "Processing fold input test\n",
      "Checking we can load the model parameters...\n",
      "Skipping data pipeline...\n",
      "Output directory: afold_test/output_gpu/test\n",
      "Writing model input JSON to afold_test/output_gpu/test\n",
      "Predicting 3D structure for test for seed(s) (1,)...\n",
      "Featurising data for seeds (1,)...\n",
      "Featurising test with rng_seed 1.\n",
      "I0722 11:34:55.003091 22835066345280 pipeline.py:164] processing test, random_seed=1\n",
      "I0722 11:34:55.034880 22835066345280 pipeline.py:257] Calculating bucket size for input with 596 tokens.\n",
      "I0722 11:34:55.034986 22835066345280 pipeline.py:263] Got bucket size 768 for input with 596 tokens, resulting in 172 padded tokens.\n",
      "Featurising test with rng_seed 1 took 7.21 seconds.\n",
      "Featurising data for seeds (1,) took  11.10 seconds.\n",
      "Running model inference for seed 1...\n",
      "Running model inference for seed 1 took  119.00 seconds.\n",
      "Extracting output structures (one per sample) for seed 1...\n",
      "Extracting output structures (one per sample) for seed 1 took  0.42 seconds.\n",
      "Running model inference and extracting output structures for seed 1 took 119.43 seconds.\n",
      "Running model inference and extracting output structures for seeds (1,) took 119.43 seconds.\n",
      "Writing outputs for test for seed(s) (1,)...\n",
      "Done processing fold input test.\n",
      "Done processing 1 fold inputs.\n"
     ]
    }
   ],
   "source": [
    "! bash {ALPHAFOLD_RUN_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974f378d-5056-46c4-9abc-0184101021e8",
   "metadata": {},
   "source": [
    "### Next steps\n",
    "\n",
    "Once the diffusion model ends with \"Done processing\" the prediction is done and we can look at the results!\n",
    "\n",
    "Keep an eye out for \"Output directory ... exists and non-empty, using instead ...\" in the cell output above, since we need the output files in the next step!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dc646a-4a53-4cc2-8a40-d812ee31aa4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
